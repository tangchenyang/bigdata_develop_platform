# 数据工程与产品
我们想象一下，有一家企业，经历了三年的从0到1野蛮生长期，取得了很大的成就，扩展了很多的客户，沉淀了很多的数据；  
同时也慢慢进入了发展缓慢期，公司规模越来越大，扩展新的业务越来越难，利润率也开始下降。  
偶然听到外界嘈杂的声音中传来的一些关键字：大数据时代，数字化转型，便将视线转向了沉淀了许久的数据，想从这一堆堆数据中挖点什么有价值的东西出来。  

## 数据工程

### 什么是数据工程

我们先看看什么是软件工程, 根据维基百科的定义，软件工程是：应用计算机科学理论和技术以及工程管理原则和方法，按预算和进度，实现满足用户要求的软件产品的定义、开发、和维护的工程或进行研究的学科。  
简而言之就是，对某一特定需求进行系统化、模块化、规范化的一个过程。  
数据工程也是如此，而数据工程的过程通常指的是：从数据的采集、存储、加工到应用的整个流程的工程化。  

### 数据工程经历了哪些时代
其实我们对数据计算或者存储的需求从古代就产生了，古时候钱庄存钱取钱背后的用算盘记账和对账等过程，与现代的数据工程如出一辙。只是相对来说需求少，体量小。
而从计算机时代以来，数据就有了翻天覆地的变化。
- 计算机时代  
在80、90年代，随着计算机慢慢普及，以及Excel的诞生，而企业财务人员的主要工具，从便携式计算器变成了小型计算机，保存数据和计算数据的主要手段也变成了Excel。  
这时候企业的用户还相对较少，产生的数据也没有特别的多，基本上一到两个财务人员就能完成公司所需的分析工作。

- 信息化时代  
在2000年左右，网页数据库等信息技术逐渐在各行各业深入应用，企业的业务流程逐渐自动化，很多企业都构建了自己的EPR系统，并且产生了很多的数据保存在数据库中。  
这个时候已经有很多BI项目和工具产生，主要是通过关系型数据库提供的计算能力，再加上web 页面的图表来做报表的展示。

- 大数据时代  
大数据时代，企业的数据从 GB 增长到 TB 甚至 PB，数据爆发式增长，传统关系型数据库如 Mysql/Oracle/SQL Server 等不能满足海量数据的计算要求  
这时候出现了很多分布式计算引擎如Hadoop/Spark，还有一些MPP架构的数据库如GreenPlum/DeepGreen/TiDB/Redshift等，这些组件的出现解决了海量数据的计算和存储的问题。  
在吞吐量不是大问题之后，很多公司开始追求时效性，也就是从批处理往流处理发展。从离线数仓到实时数仓，从数据仓库到数据湖，也衍生了很多流批一体的架构如Lambda架构和Kappa架构等等。  
从战略角度来看，从CRM 发展到 DMP，从DMP 到CDP，再到数据中台，再到 数据网格 DataMesh。在这个时代爆发出了各种让人眼花缭乱的产品或者解决方案。。
本篇文章我们就简单介绍一下这些跟数据息息相关的内容。


### 数据工程包括哪些内容
有需求就会有市场，那我们先来看看都有哪些数据/大数据相关的岗位  
- 大数据平台开发工程师
- 大数据开发工程师  
- 数据开发工程师
- 数据仓库工程师
- ETL工程师
- 数据平台开发工程师
- 数据分析师
- 数据挖掘工程师
- 数据科学家
- 算法/机器学习工程师 等


## 大数据开发平台
所有的软件都要运行在硬件之上，而大数据的计算也都要运行在各种大数据组件之上，各种大数据组件集成起来提供数据计算能力的这集合，就是大数据开发平台。
大数据平台为数据工程师或者数据分析师等提供数据的开发能力（如计算、存储、分析、安全审计、监控告警等），在此平台之上做各种各样的数据开发

- 自建平台/私有云  
企业自己采购硬件、搭建机房、维护设备、维护软件等所有人力和经济成本，均由企业自己承担。
这里没有将自建平台和私有云做区分，是因为相对于企业自身来说，都需要投入相同的成本，区别只是这个工作是在不同的部门而已。
  - 优点
    - 网络只对本地开放，安全性高
    - 自定义程度高，灵活性高
    - 可控性更高，服务器类型，软件版本等可以深度自定义
    - 可以本地开发
  - 缺点
    - 运维成本高，需要为更多的基础设施付费，需要独立的运维团队
  - 例子
    - 自建 HUAWEI FusionInsight 集群
    - 自建 CDH 集群等
- 云平台  
企业租赁云厂商提供的PaaS服务，在此服务之上直接做数据开发
  - 优点
    - 开箱即用，无需太多额外的运维成本
    - 按需付费，弹性扩容，无需在前期就投入大量的技术设施成本
  - 缺点
    - 安全性不如本地自建平台，服务器在公网上，需要定义防火墙规则来限制访问，极小可能存在被侵入的风险
    - 灵活性较差，PaaS提供的组件组合以及版本往往是固定的，并且几乎不可能使用到最新版本的开源组件
  - 例子
    - AWS 
    - Azure 
    - 阿里云 等

## 数据平台
有了大数据开发平台，但测试这个平台只是具备了数据开发的能力，并没有提供任何数据。  
用户想要做分析的时候还是需要经过繁琐的数据导入、数据清晰、建模等繁琐的过程，才能够真正地使用数据。  
而数据平台的出现就是为了解决这些问题，为企业的数据分析挖掘、商业洞察、战略决策提供统一的、标准的、集成的、可靠的、易用的数据支撑服务。  
常见的数据平台有数据仓库、数据湖、数据中台等，我们来看一看他们的异同。  
### 数据仓库  
数据仓库是诞生比较早的数据平台，广义上来说它不是一种具体的技术，而是一种方法、一套架构。它可以构建在如MySql/Oracle等传统的RDBMS上，也可以构建在如Hadoop、Hive等分布式架构之上。  
数据仓库主要是针对特定主题的结构化的数据，SQL是主要语言，一般采用维度建模的方式，有清晰完善的层级结构，主要包括ODS层、DW层、ADS层。  
#### 数据仓库分层
我们来看一张数据仓库层级图  
![数据仓库分层](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240716/image.1vyjgsxxt0.webp)  

- ODS 层  
ODS(Operational Data Store)层又称贴源层, 是从外部系统将操作型数据导入平台之后的第一层，保存了操作型数据最原始的状态。  
数据从这一层开始将各种外部数据集成在数据平台中，并且无需重复从外部数据中重复采集相同的数据。  

- DW 层  
DW(Data Warehouse)层，是数仓中最核心的一个层级，其中包含维度层 DIM, 数据明细层 DWD, 数据服务层 DWS
  - DIM (Dimension)  
    维度表中主要用来存放一些具有确定含义、不会随着业务发生变化的的维度信息，如时间维度、地区维度、用户维度、商品维度
    其中如用户维度、商品维度等，虽然不会随着业务发生快速变化，但可能会随着公司发展阶段，用户体量等因素而缓慢变化，因此又被细分为缓慢变化维度 SCD  
    应对 SCD 的手段有很多种，如常用的拉链表等，这里不过多介绍，更多请参考 [Wiki: Slowly changing dimension](https://en.wikipedia.org/wiki/Slowly_changing_dimension)
  - DWD (Data Warehouse Details)   
    明细表中主要存放业务明细数据，在建模的过程中会做一些标准化处理，和维度退化处理：仅保留维度主键，在分析过程中，一个维度除了主键外，其他维度信息不参与计算，节省资源的同时，也可以让数据分析工作更加聚焦在业务，不受其他维度信息的干扰。   
    
  - DWS (Data Warehouse Service)  
    数据服务层按照部门的业务需求进行处理，产生的结果是针对特定主体的，如按雪花模型或星型模型做关联形成大宽表，便于进一步的数据分析，或按照特定维度(如以年/月的时间维度)做聚合，形成相对公共的汇总数据等。 
  
- ADS 层  
ADS(Application Data Store)层，是面向应用的最顶层，上层应用直接从ADS层获取特定需求的结果数据，无需再在上层应用做额外的计算。  
由于对接各种各样的上层应用，ADS层的数据也是多种多样，有按维度深度汇总的报表数据，便于BI团队做可视化；有按照业务属性将DWS表做深度关联，便于OLAP团队做即席查询，便于ML团队做数据挖掘；也有按指标模型构建的标签数据，方便运营团队做精细化运营，进准营销等等。  
理想的情况，上层应用的每一个报表、或者其他依赖数据的服务，都对应着一张ADS层单独的表。  
#### 离线数据仓库架构
数据仓库早期主要聚焦在离线计算上，数据窗口可能以月甚至年为单位，延迟多为T+1，即当天能看到前一天的数据即可。  
我们来一张离线数据仓库架构图  
![离线数据仓库架构](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240719/image.86tjiu2bbt.webp)
![离线数据仓库架构](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240719/image.92q0ycab1r.webp)
HDFS 作为分布式文件存储系统，存储能力可以近似认为无限；  
Spark 作为分布式内存计算框架，计算能力也可以通过扩展节点来提升，从而支持处理任意规模的数据；
Hive 作为数据仓库组件，是集中管理数据仓库模型中各种数据库和表的地方，其数据存储在HDFS上，计算引擎默认是MapReduce，也可用Spark进行替换，以提升处理性能。  
离线数仓使用的技术决定了其能够支持大规模数据集的计算，也导致其具有相对较高的延迟，在准实时计算领域发挥受到限制。  

#### 实时数据仓库架构
为了能让数据仓库的延迟更低，让业务洞察的反馈更快，实时数仓应运而生  
我们再来看一张实时数仓架构图  
![实时数据仓库架构](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240719/image.26lde5yylh.webp)
实数数仓中替换了造成延迟的主要组件，将批计算引擎换成流计算引擎，将离线数据仓库组件换成更为实时的消息中间件
Kafka 作为流处理中的消息中间件，不同层级的不同的topic中保存不同属性的数据；  
SparkStreaming 或 Flink 作为实时计算框架，能够让单个作业的延迟最低控制在秒级； 
由于流式处理组件的特性，整个链路的延迟能控制在分钟级甚至秒级，但一般只处理增量数据，数据准确性相对不如离线计算。  
为了同时满足批处理和流处理两个场景，也催化了一些流批一体的架构  

#### Lambda 架构
Lambda 架构是由离线数仓和实时数仓两部分组成的，从需求上同时满足了全量数据和增量数据的计算，并在准确性和效率上取得了平衡  
先看一张Lambda架构图  
![Lambda架构](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240719/image.361grfu29l.webp)
同一个指标模型同时在Batch Layer和RealTime Layer中进行相同的逻辑，分别产生Batch Table 和 RealTime Table, Server Layer 层将两个用Union或其他方式进行合并，最为最终的ADS层。  
Batch Layer中的数据为全量的数据，计算出来的结果更加准确，但最多只能显示昨天的数据；RealTime Layer 对今天的增量数据做补充，来提升数据的实时性，
但可能会由于数据的变更（比如交易关闭，订单取消等，需要对历史数据进行重新计算等场景）导致数据准确性不高, 需要再第二天的Batch Layer中重新计算，或可称之为数据校准。  
因此在 Server Layer 将 Batch Table 昨天的数据和 RealTime Table 今天的数据进行合并， 从而兼顾实时性和准确性。  
显而易见，Lambda架构的缺点也非常明显，就是需要同时维护两套相同业务逻辑的代码，并且技术栈都不太一样，导致开发成本、维护成本以及资源成本都相对较高。  
为了解决 Lambda 架构下的痛点，LinkedIn 提出了 Kappa 架构  

#### Kappa 架构
Kappa 架构的核心思路是，删除Batch Layer，改进Lambda架构中的Speed Layer，使其能够支持历史数据的计算
从架构上采用了纯实时架构，架构图可以参考 [实时数据仓库架构](#实时数据仓库架构) 章节
Kappa 架构认为在保证处理流程完善的前提下，增量计算的数据就是准确的，通常不需要对历史数据进行计算，只有很少的场景需要重算所有数据。  
消息队列中的消息通常具有时效性，为了支持重新计算，需要从业务库或者备份库重新拉取全量数据。  
并且为实时数仓中的Topic创建一个孪生Topic，用来保存计算历史数据时的中间层级的数据，避免污染运行中的作业模型。  
在需要重新计算时，只需要启动一个额外的任务，将消费的偏移量设置为0，即可从头开始消费，从而重新计算所有的数据。 
不难看出Kappa架构对消息中间件的要求非常高，需要很高的吞满足计算全量的数据；并且不像离线数据仓库那样，可以查询任意层级，实现灵活的OLAP需求；同时做数据治理的难度很大，比如数据血缘的管理，数据权限的管理等；

#### 数据仓库痛点
从上述的分层结构可以看出，不管是离线数仓还是实时数仓，都有着非常规范的结构，和较高的数据质量。
但缺点也比较明显，数仓团队需要为每一个特定主题的数据来在不同层级构建不同的表，从需求提出，到数据可用，所经历的周期相对较长。 
数据基本上都是外部系统中的结构化数据，且都是先有需求再建模，整体提供的数据服务能力呈收敛的状态，相对不太容易能挖掘出更多的价值。  
为了解决这些痛点，数据湖的架构慢慢发展起来。  

### 数据湖
数据湖(Data Lake)名字也比较形象，顾名思义它可以容纳各种各样的数据，如结构化数据(Table)、半结构化数据(JSON、XML、HTML)以及非结构化数据(文件，音频，视频等)  
数据湖通常会统一存储企业的所有数据，既包括采集后的原始数据，也包括转换后的数据，转换的层级可以很少（甚至为零），也可以按照严格的层级进行建模，故而数据仓库可以是数据湖的一个真子集，也就是常见的湖仓一体架构。  
也因为可以不受严格的层级约束，数据入湖提供服务的技术成本和时间成本都大大降低，数据湖可以很轻松地整合各种各样的企业内部数据或者第三方数据，从而打破数据孤岛；同时视数据的情况可以按需进行数据转换，甚至在数据比较规范及安全的情况下，无需转换直接向下游提供数据服务，加速数据产生价值的时间。  
我们再来看数据湖层级图  
![数据湖层级图](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240716/image.6pnecxbeaq.webp)  
所以数据湖相对于数据仓库来说，可以面向任意业务，授权用户可以以任意速度，任意语言，访问数据湖的任意层级的数据。  
广义上的数据湖是一套架构，一套体系，一套完整的方法论，而狭义上的数据湖则是由这套架构催化的存储数据的具体的技术组件。
离线数据仓库中的操作多为文件操作，仅支持读和写，不支持更新；即使可以通过逻辑层面实现更新的功能，本质上也是将整个文件删除和覆写，延迟相对较高，在准实时场景下容易成为性能瓶颈。  
行业头部公司为了解决这些痛点，各自出现了自己的解决方案，比较知名的 Databrics 的 Dalta Lake，Uber 开源的 Hudi，Netflix 开源的 Iceberg，也就是常说的"数据湖三剑客"。  
它们的核心都是定义了一种全新的表格式，即在对分布式文件系统之上做了一层封装，对文件进行标记，区分有效数据或已删除数据，通过引入一级索引文件和二级索引文件来对数据进行文件级的过滤和整合，从而实现快速ACID的语义。  


### 数据中台 
数据中台是企业级能力复用和赋能平台, 是数据驱动业务场景下孵化的产物, 以一种标准的、安全的、可靠的、统一的、共享的、解耦的、服务化的方式支持前端数据的应用。
数据是业务的一种展现形式，业务是产生数据的途径或者手段，当企业的业务足够复杂时，不同的业务部门就无可避免地就产生一些重复的业务模型，并产生重复的数据模型  
比如阿里巴巴旗下有淘宝、天猫、咸鱼等等不同的产品，每个产品都会涉及到销售、订单、物流、支付等一系列业务。如果对每一个产品的每一个业务模型进行数据平台层面的建模，可想而知重复的工作非常之多，模型建设各自孤立，数据标准难以统一，并且想推出一个新产品时，这些重复的工作也不可避免地需要重做一次。  
随着用户数量的增长、用户消费习惯的改变、以及市场的多变，传统的数据平台难以及时作出调整，无法快速为业务提供数据支撑，这时就需要一个能够快速响应市场变化的统一的企业级平台架构。  
而也随着微服务的实践越来越成熟，我们不难想到，可以用微服务的思想来解决这类问题，将可复用的业务能力，按DDD（领域驱动设计）的原则对业务进行拆分和重组，形成一个统一的业务中台；再对产生的领域数据进行统一建模，产生的指标数据反哺到业务中去，即可形成一个统一的数据中台。  
这也就是 DataMesh 的核心思路 (数据平台 + 领域驱动设计 + 微服务 = 数据中台), 数据中台是道，是企业级战略思想；DataMesh 是法，是技术方法论；数据工程、微服务等是术, 是建设中台的手段；各项技术组件是器，是建设中台的工具。      
![数据中台架构图](https://github.com/tangchenyang/picx-images-hosting/raw/master/20240719/image.4xuftvkwoq.webp)  
可以看出，数据中台的建设成本高，周期长，不是一个或者几个部门能短时间就能完成的事情，它需要企业各个部门之间协作，对齐目标和愿景，从企业顶层视角进行统一设计和建设。  
因此，在中小型企业，业务没有那么复杂，并且传统数仓或数据湖架构能够满足战略目标时，数据中台的建设反而会引入过高的技术/架构复杂度和综合成本。
介绍完技术视角的数据平台，我们来看看业务视角下的数据产品。  

## 数据产品 
数据产品就是，能够为用户提供数据服务，产生直接或间接价值的应用或者系统。    
前面所讲到的数据平台都能够为企业提供数据服务，也可以称之为数据产品，但是主要关注在技术视角，即如何利用技术来完成平台的建设，以满足业务需求。    
我们来看看从业务视角的定位，有哪些数据产品  
### CRM  
CRM(Custom Relationship Management)系统，是管理客户数据的平台，向企业或营销方提供管理或分析上下游，客户渠道，营销情况等能力。  
- 特点
  - 管理上下游之间的数据
  - 高时效性：业务数据低延迟
- 使用场景
  - 营销，销售等领域的客户管理、上下游/供应链管理等
- 案例:
  - 纷享销客CRM, Salesforce, Zuora  
  
### DMP 
DMP(Data Management Platform)，其定位主要是通过标签体系和圈选人群来提供精准投放的服务。   
- 特点
  - 管理用户标签数据
  - 匿名数据，只关心用户群体，不关心具体的用户
- 使用场景
  - 电商平台，内容平台等定向推送
- 案例
  - 淘宝-达摩盘, 抖音-巨量千川

### CDP
CDP(Custom Data Platform)系统，是客户数据的管理和分析平台，CDP包含CRM和DMP提供的能力，并通过对数据的分析和挖掘，来向企业提供精细化运营的能力。  
- 特点
  - CRM + DMP + 精细化运营
- 使用场景
  - 管理企业客户数据，上下游数据等
  - 广告投放
  - 分析和优化现有业务营收及投入成本，降本增效，实现精细化运营。
  - 商业洞察和战略规划
- 案例
  - 各个企业的数据平台，企业年报背后的技术支撑平台
  - GENE DataLake - MCDP

以上几个数据产品都只聚焦在数据能为用户带来的价值，通常产品经理需要考虑自己需要哪一类数据产品；
而其底层是使用传统数据库还是需要建设数据平台，则需要数据架构师来根据企业的战略规划来选择最适合的平台架构。 

## 数据工程的价值
### 一般企业如何产生价值
- 商贸企业：  
  经营模式主要为：采购 -> 销售，特点是成本低，利润低，周期短，比如超市，服装经销等。  
- 生产企业：   
  经营模式主要为：采购原材料 -> 生产加工 -> -> 销售，特点是成本低，利润高，周期长；比如产品型公司，如护肤品厂商，服装厂商等。  
- 互联网企业：  
  经营模式主要为：开发软件 -> 销售软件/提供服务； 按使用收费: 前期投入高，边际成本低，用户多，利润高；如电商平台，外卖平台，内容平台等。  
### 数据产品如何产生价值
- 直接价值  
目前数据交易的法律法规还在逐步完善，能够直接提供价值的数据产品并不多  
能够提供数据赋能的服务: 如CRM-SaaS，以及用于精准投放的DMP数据包等  
- 间接价值  
大部分数据产品都是间接提供价值，即通过数据分析和挖掘等手段，为上层应用提供分析或决策数据，数据从业务中来，反哺到业务中去，降本增效，优化现有业务，帮助上层应用实现价值增长。  
  - CRM: 精细化运营，提升运营效率，提升用户粘性，淘汰低ROI业务线等
  - DMP: 精准营销, 广告投放
  - CDP: CRM + DMP + More： 风险预警，数据分析和挖掘，ML + AI等。
- 创新价值
数据中台与其他数据产品相比，有其天然的优势，即通过数据资产或业务能力的复用和重组，来实现组合式创新，扩展新的业务线。
如盒马鲜生的诞生，通过复用和组合中台的用户、交易、支付等现有业务能力，形成了线上线下一体的新零售业务线。  
反观盒马先生的经营模式，也基本上都是已有业务的不同形态的组合。也因为这一点，数据中台往往也只能实现组合式创新，很难做到颠覆式创新。
- 颠覆式创新
在 ChatGPT 问世之前，ML和AI发展了很长一段时间，但是用户从中获益甚少，基本上处于玩具级定位，人工智能被广大用户戏称为人工智障。  
随着算力的发展和数据的累积以及对算法的掌握，2022年ChatGPT问世之后，NLP(自然语言处理)领域有了全新的突破，同时也掀起了大模型的浪潮，图像领域、视频领域、音频领域等各种大模型爆发式出现。  
庞大的数据体量以及对数据的应用，在接下来的人工智能时代的数据训练将会扮演非常重要的角色。
我们也来期待一下AI会给我们带来怎样的创新。 
